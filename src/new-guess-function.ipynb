{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "talented-liberia",
   "metadata": {},
   "source": [
    "# New guess function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "progressive-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import enum\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import pi\n",
    "from qiskit import Aer, QuantumRegister, ClassicalRegister, QuantumCircuit, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "artificial-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuessStrategy(enum.Enum):\n",
    "    one_bit_same_as_measured = 1\n",
    "    two_bit_base = 2\n",
    "    two_bit_neural_network = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identified-springer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_lambda_used_one_bit_strategy(counts: str) -> int:\n",
    "    \"\"\" Decides which lambda was used on the real execution from the one bit 'counts' measured\n",
    "        It is a silly guess.\n",
    "        It returns the same lambda index used as the measured result\n",
    "    \"\"\"\n",
    "    if len(counts) != 1:\n",
    "        raise ValueError('counts MUST be a one character length string')\n",
    "    if \"0\" in counts:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stone-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_lambda_used_two_bit_strategy(counts: str) -> int:\n",
    "    \"\"\" Decides which lambda was used on the real execution from the two 'counts' measured\n",
    "        Setting eta0 >= eta1:\n",
    "            * outcome 00 -> eta1 as the most probable (more attenuation)\n",
    "            * outcome 01 -> eta0 as the most probable (less attenuation) \n",
    "            * outcome 10 -> 50% chance, random choice\n",
    "            * outcome 11 -> not possible, but in case we get it (from noisy simulation), 50% chance, random choice\n",
    "    \"\"\"\n",
    "    if len(counts) != 2:\n",
    "        raise ValueError('counts MUST be a two character length string')\n",
    "    if counts == \"00\":\n",
    "        return 1\n",
    "    if counts == \"01\":\n",
    "        return 0\n",
    "    if counts == \"10\" or counts == \"11\":\n",
    "        return random.choice([0,1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "above-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measured_value_from_counts(counts_dict: dict) -> str:\n",
    "    \"\"\" converts the dictionary counts measured to the\n",
    "        value measured in string format\n",
    "    \"\"\"\n",
    "    if len(list(counts_dict.keys())) != 1:\n",
    "        raise ValueError('Circuit execution shots MUST be 1')\n",
    "    return list(counts_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "western-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_counts_to_lambda_used(counts_dict: dict, guess_strategy: GuessStrategy = GuessStrategy.one_bit_same_as_measured) -> int:\n",
    "    \"\"\" Decides which lambda was used on the real execution from the 'counts' measured\n",
    "        based on the guess strategy that is required to use\n",
    "    \"\"\"\n",
    "    if (guess_strategy != GuessStrategy.one_bit_same_as_measured and \n",
    "        guess_strategy != GuessStrategy.two_bit_base and \n",
    "        guess_strategy != GuessStrategy.two_bit_neural_network):\n",
    "            raise ValueError('Invalid Guess Strategy')\n",
    "\n",
    "    counts = get_measured_value_from_counts(counts_dict)\n",
    "    \n",
    "    if guess_strategy == GuessStrategy.one_bit_same_as_measured:\n",
    "        return guess_lambda_used_one_bit_strategy(counts)\n",
    "    if guess_strategy == GuessStrategy.two_bit_base:\n",
    "        return guess_lambda_used_two_bit_strategy(counts)\n",
    "    if guess_strategy == GuessStrategy.two_bit_neural_network:\n",
    "        raise NotImplementedError('Guess Strategy not implemented yet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecological-yukon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_damping_channel_measuring_one_qubit() -> int:\n",
    "    theta = pi/4\n",
    "    attenuation_factor = 0.4\n",
    "    \n",
    "    backend = backend = Aer.get_backend('qasm_simulator')\n",
    "    qreg_q = QuantumRegister(2, 'q')\n",
    "    creg_c = ClassicalRegister(1, 'c')\n",
    "\n",
    "    initial_state = (math.cos(theta), math.sin(theta))\n",
    "\n",
    "    circuit = QuantumCircuit(qreg_q, creg_c)\n",
    "    circuit.initialize([initial_state[0],\n",
    "                        initial_state[1]], qreg_q[0])\n",
    "    circuit.reset(qreg_q[1])\n",
    "    circuit.cry(2 * np.arcsin(np.sqrt(attenuation_factor)), qreg_q[0], qreg_q[1])\n",
    "    circuit.cx(qreg_q[1], qreg_q[0])\n",
    "    circuit.rx(0, qreg_q[0])\n",
    "    circuit.ry(0, qreg_q[0])\n",
    "    circuit.measure(qreg_q[0], creg_c[0])\n",
    "\n",
    "    counts = execute(circuit, backend, shots=1).result().get_counts(circuit)\n",
    "    print(f'counts returned: {counts}')\n",
    "    return convert_counts_to_lambda_used(counts, guess_strategy=GuessStrategy.one_bit_same_as_measured)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "excessive-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_damping_channel_measuring_two_qubits() -> int:\n",
    "    theta = pi/4\n",
    "    attenuation_factor = 0.4\n",
    "    \n",
    "    backend = backend = Aer.get_backend('qasm_simulator')\n",
    "    qreg_q = QuantumRegister(3, 'q')\n",
    "    creg_c = ClassicalRegister(2, 'c')\n",
    "\n",
    "    initial_state = (0, math.cos(theta), math.sin(theta), 0)\n",
    "\n",
    "    circuit = QuantumCircuit(qreg_q, creg_c)\n",
    "    circuit.initialize(initial_state, [0, 1])\n",
    "    circuit.reset(qreg_q[2])\n",
    "    circuit.cry(2 * np.arcsin(np.sqrt(attenuation_factor)), qreg_q[1], qreg_q[2])\n",
    "    circuit.cx(qreg_q[2], qreg_q[1])\n",
    "    circuit.rx(1, qreg_q[1])\n",
    "    circuit.ry(1, qreg_q[1])\n",
    "    circuit.measure([0, 1], creg_c)\n",
    "\n",
    "    counts = execute(circuit, backend, shots=1).result().get_counts(circuit)\n",
    "    print(f'counts returned: {counts}')\n",
    "    return convert_counts_to_lambda_used(counts, guess_strategy=GuessStrategy.two_bit_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "static-moral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts returned: {'0': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_damping_channel_measuring_one_qubit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "entire-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts returned: {'00': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_damping_channel_measuring_two_qubits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smaller-palestinian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
